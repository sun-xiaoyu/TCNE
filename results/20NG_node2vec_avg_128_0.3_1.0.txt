20NG 128 node2vec 0.3 1.0
Fri May  3 23:41:46 2019. At 24951 s, node(word) embeddings trained/read from file.
Fri May  3 23:41:50 2019. At 24954 s, feature matrix generated
Fri May  3 23:45:41 2019. At 25186 s, svm model trained/read from file

Features shape:(11293, 128)
Accuracy in training set:0.8267953599574958
Macro:(0.8244822216343023, 0.8179903099711261, 0.8168611146495373, None)
Micro:(0.8267953599574958, 0.8267953599574958, 0.8267953599574958, None)
                          precision    recall  f1-score   support

             alt.atheism     0.8337    0.7937    0.8132       480
           comp.graphics     0.7287    0.7175    0.7230       584
 comp.os.ms-windows.misc     0.7080    0.7290    0.7183       572
comp.sys.ibm.pc.hardware     0.6858    0.6068    0.6439       590
   comp.sys.mac.hardware     0.7542    0.7699    0.7620       578
          comp.windows.x     0.8090    0.8499    0.8289       593
            misc.forsale     0.7487    0.7641    0.7563       585
               rec.autos     0.8603    0.8603    0.8603       594
         rec.motorcycles     0.9008    0.9114    0.9061       598
      rec.sport.baseball     0.9480    0.9464    0.9472       597
        rec.sport.hockey     0.9450    0.9733    0.9589       600
               sci.crypt     0.9219    0.9328    0.9273       595
         sci.electronics     0.7702    0.6920    0.7291       591
                 sci.med     0.9013    0.9377    0.9191       594
               sci.space     0.8835    0.9207    0.9017       593
  soc.religion.christian     0.7335    0.9114    0.8128       598
      talk.politics.guns     0.8540    0.9119    0.8820       545
   talk.politics.mideast     0.9123    0.9592    0.9352       564
      talk.politics.misc     0.8026    0.7871    0.7948       465
      talk.religion.misc     0.7880    0.3846    0.5169       377

               micro avg     0.8268    0.8268    0.8268     11293
               macro avg     0.8245    0.8180    0.8169     11293
            weighted avg     0.8256    0.8268    0.8229     11293

Accuracy in testing set:0.755413843496745
Macro test:(0.7511073613881482, 0.7433117215522521, 0.7416953336258532, None)
Micro test:(0.755413843496745, 0.755413843496745, 0.755413843496745, None)
                          precision    recall  f1-score   support

             alt.atheism     0.6555    0.6144    0.6343       319
           comp.graphics     0.6530    0.7352    0.6917       389
 comp.os.ms-windows.misc     0.6523    0.6539    0.6531       393
comp.sys.ibm.pc.hardware     0.5989    0.5485    0.5726       392
   comp.sys.mac.hardware     0.6368    0.6649    0.6506       385
          comp.windows.x     0.7967    0.7398    0.7672       392
            misc.forsale     0.7653    0.7359    0.7503       390
               rec.autos     0.8240    0.8177    0.8208       395
         rec.motorcycles     0.8818    0.8995    0.8905       398
      rec.sport.baseball     0.9121    0.8892    0.9005       397
        rec.sport.hockey     0.9315    0.9549    0.9431       399
               sci.crypt     0.8529    0.8788    0.8657       396
         sci.electronics     0.6497    0.6183    0.6336       393
                 sci.med     0.8550    0.8636    0.8593       396
               sci.space     0.8177    0.8426    0.8300       394
  soc.religion.christian     0.6731    0.8794    0.7625       398
      talk.politics.guns     0.6603    0.8599    0.7470       364
   talk.politics.mideast     0.8871    0.8564    0.8714       376
      talk.politics.misc     0.6488    0.5065    0.5688       310
      talk.religion.misc     0.6696    0.3068    0.4208       251

               micro avg     0.7554    0.7554    0.7554      7527
               macro avg     0.7511    0.7433    0.7417      7527
            weighted avg     0.7553    0.7554    0.7510      7527
Fri May  3 23:45:42 2019. At 25186 s, all done.
