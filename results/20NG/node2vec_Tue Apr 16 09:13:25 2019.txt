
Features shape:(11293, 125)
Accuracy in training set:0.8217479854777295
Macro:(0.8203694825237896, 0.8118062974044383, 0.810015791994459, None)
Micro:(0.8217479854777295, 0.8217479854777295, 0.8217479854777295, None)
Accuracy in testing set:0.7499667862362163
Macro test:(0.7449746512841353, 0.7377090993932914, 0.7355780533192994, None)
Micro test:(0.7499667862362163, 0.7499667862362163, 0.7499667862362163, None)
                          precision    recall  f1-score   support

             alt.atheism     0.6982    0.6238    0.6589       319
           comp.graphics     0.6553    0.6941    0.6742       389
 comp.os.ms-windows.misc     0.6224    0.6209    0.6217       393
comp.sys.ibm.pc.hardware     0.5930    0.6020    0.5975       392
   comp.sys.mac.hardware     0.6738    0.6545    0.6640       385
          comp.windows.x     0.7668    0.7551    0.7609       392
            misc.forsale     0.7769    0.7231    0.7490       390
               rec.autos     0.7956    0.8278    0.8114       395
         rec.motorcycles     0.8747    0.8593    0.8669       398
      rec.sport.baseball     0.9165    0.9118    0.9141       397
        rec.sport.hockey     0.9270    0.9549    0.9407       399
               sci.crypt     0.8290    0.8813    0.8543       396
         sci.electronics     0.6398    0.5649    0.6000       393
                 sci.med     0.8081    0.8611    0.8337       396
               sci.space     0.7957    0.8503    0.8221       394
  soc.religion.christian     0.6789    0.8819    0.7672       398
      talk.politics.guns     0.6444    0.8462    0.7316       364
   talk.politics.mideast     0.8939    0.8511    0.8719       376
      talk.politics.misc     0.6724    0.5032    0.5756       310
      talk.religion.misc     0.6372    0.2869    0.3956       251

               micro avg     0.7500    0.7500    0.7500      7527
               macro avg     0.7450    0.7377    0.7356      7527
            weighted avg     0.7488    0.7500    0.7448      7527
