20NG 128 deepWalk 8 
Tue May 21 16:31:27 2019. At 2708 s, node(word) embeddings trained/read from file.
Tue May 21 16:31:30 2019. At 2711 s, feature matrix generated
Tue May 21 16:36:23 2019. At 3003 s, svm model trained from file

Features shape:(11293, 128)
Accuracy in training set:0.8291862215531746
Macro:(0.8250082251460856, 0.8208801271771898, 0.819809199679138, None)
Micro:(0.8291862215531746, 0.8291862215531746, 0.8291862215531746, None)
                          precision    recall  f1-score   support

             alt.atheism     0.8047    0.7896    0.7971       480
           comp.graphics     0.7447    0.7243    0.7344       584
 comp.os.ms-windows.misc     0.7248    0.7413    0.7329       572
comp.sys.ibm.pc.hardware     0.6606    0.6102    0.6344       590
   comp.sys.mac.hardware     0.7232    0.7232    0.7232       578
          comp.windows.x     0.8418    0.8617    0.8517       593
            misc.forsale     0.7438    0.7744    0.7588       585
               rec.autos     0.8451    0.8451    0.8451       594
         rec.motorcycles     0.8966    0.9130    0.9047       598
      rec.sport.baseball     0.9598    0.9598    0.9598       597
        rec.sport.hockey     0.9575    0.9767    0.9670       600
               sci.crypt     0.9182    0.9429    0.9303       595
         sci.electronics     0.7472    0.6853    0.7149       591
                 sci.med     0.9187    0.9512    0.9347       594
               sci.space     0.8801    0.9157    0.8975       593
  soc.religion.christian     0.7798    0.9181    0.8433       598
      talk.politics.guns     0.8330    0.8972    0.8640       545
   talk.politics.mideast     0.9363    0.9645    0.9502       564
      talk.politics.misc     0.8293    0.8151    0.8221       465
      talk.religion.misc     0.7549    0.4085    0.5301       377

               micro avg     0.8292    0.8292    0.8292     11293
               macro avg     0.8250    0.8209    0.8198     11293
            weighted avg     0.8269    0.8292    0.8257     11293

Accuracy in testing set:0.7433240334794738
Macro test:(0.7339398431324236, 0.73073250347941, 0.7291084413018835, None)
Micro test:(0.7433240334794738, 0.7433240334794738, 0.7433240334794738, None)
                          precision    recall  f1-score   support

             alt.atheism     0.6589    0.6176    0.6375       319
           comp.graphics     0.6348    0.7506    0.6879       389
 comp.os.ms-windows.misc     0.6545    0.6412    0.6478       393
comp.sys.ibm.pc.hardware     0.5761    0.5408    0.5579       392
   comp.sys.mac.hardware     0.6040    0.6260    0.6148       385
          comp.windows.x     0.7665    0.7704    0.7684       392
            misc.forsale     0.7282    0.7282    0.7282       390
               rec.autos     0.8035    0.8076    0.8056       395
         rec.motorcycles     0.8727    0.8442    0.8582       398
      rec.sport.baseball     0.9152    0.8967    0.9059       397
        rec.sport.hockey     0.9418    0.9323    0.9370       399
               sci.crypt     0.8507    0.8636    0.8571       396
         sci.electronics     0.6316    0.6107    0.6210       393
                 sci.med     0.8605    0.8258    0.8428       396
               sci.space     0.8278    0.8782    0.8522       394
  soc.religion.christian     0.6850    0.8744    0.7682       398
      talk.politics.guns     0.6591    0.8022    0.7237       364
   talk.politics.mideast     0.8876    0.8404    0.8634       376
      talk.politics.misc     0.6581    0.4968    0.5662       310
      talk.religion.misc     0.4621    0.2669    0.3384       251

               micro avg     0.7433    0.7433    0.7433      7527
               macro avg     0.7339    0.7307    0.7291      7527
            weighted avg     0.7412    0.7433    0.7396      7527
Tue May 21 16:36:23 2019. At 3003 s, all done.
