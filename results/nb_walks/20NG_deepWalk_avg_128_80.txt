20NG 128 deepWalk 80 
Wed May 22 12:33:09 2019. At 14029 s, node(word) embeddings trained/read from file.
Wed May 22 12:33:12 2019. At 14031 s, feature matrix generated
Wed May 22 12:37:13 2019. At 14273 s, svm model trained from file

Features shape:(11293, 128)
Accuracy in training set:0.8295404232710528
Macro:(0.8260721522262381, 0.819059620026706, 0.81655729786404, None)
Micro:(0.8295404232710528, 0.8295404232710528, 0.8295404232710527, None)
                          precision    recall  f1-score   support

             alt.atheism     0.8017    0.7750    0.7881       480
           comp.graphics     0.7517    0.7414    0.7466       584
 comp.os.ms-windows.misc     0.7385    0.7605    0.7494       572
comp.sys.ibm.pc.hardware     0.7250    0.6390    0.6793       590
   comp.sys.mac.hardware     0.7585    0.7336    0.7458       578
          comp.windows.x     0.8170    0.8735    0.8443       593
            misc.forsale     0.7554    0.7761    0.7656       585
               rec.autos     0.8295    0.8519    0.8405       594
         rec.motorcycles     0.9028    0.9013    0.9021       598
      rec.sport.baseball     0.9578    0.9514    0.9546       597
        rec.sport.hockey     0.9481    0.9750    0.9614       600
               sci.crypt     0.9039    0.9328    0.9181       595
         sci.electronics     0.7930    0.6870    0.7362       591
                 sci.med     0.9081    0.9478    0.9275       594
               sci.space     0.8808    0.9342    0.9067       593
  soc.religion.christian     0.7382    0.9431    0.8282       598
      talk.politics.guns     0.8102    0.9009    0.8532       545
   talk.politics.mideast     0.9169    0.9592    0.9376       564
      talk.politics.misc     0.8243    0.7871    0.8053       465
      talk.religion.misc     0.7597    0.3103    0.4407       377

               micro avg     0.8295    0.8295    0.8295     11293
               macro avg     0.8261    0.8191    0.8166     11293
            weighted avg     0.8280    0.8295    0.8243     11293

Accuracy in testing set:0.7578052344891724
Macro test:(0.7487332480160689, 0.7439097166222082, 0.7405891025091702, None)
Micro test:(0.7578052344891724, 0.7578052344891724, 0.7578052344891724, None)
                          precision    recall  f1-score   support

             alt.atheism     0.6920    0.5987    0.6420       319
           comp.graphics     0.6909    0.7584    0.7230       389
 comp.os.ms-windows.misc     0.6909    0.6768    0.6838       393
comp.sys.ibm.pc.hardware     0.5932    0.5765    0.5847       392
   comp.sys.mac.hardware     0.6517    0.6416    0.6466       385
          comp.windows.x     0.7704    0.7704    0.7704       392
            misc.forsale     0.7731    0.7513    0.7620       390
               rec.autos     0.8259    0.8405    0.8331       395
         rec.motorcycles     0.8807    0.8719    0.8763       398
      rec.sport.baseball     0.9137    0.9068    0.9102       397
        rec.sport.hockey     0.9246    0.9524    0.9383       399
               sci.crypt     0.8557    0.8838    0.8696       396
         sci.electronics     0.6199    0.5852    0.6021       393
                 sci.med     0.8535    0.8535    0.8535       396
               sci.space     0.8213    0.8985    0.8582       394
  soc.religion.christian     0.6762    0.8920    0.7692       398
      talk.politics.guns     0.6559    0.8379    0.7358       364
   talk.politics.mideast     0.8613    0.8590    0.8602       376
      talk.politics.misc     0.6522    0.4839    0.5556       310
      talk.religion.misc     0.5714    0.2390    0.3371       251

               micro avg     0.7578    0.7578    0.7578      7527
               macro avg     0.7487    0.7439    0.7406      7527
            weighted avg     0.7543    0.7578    0.7516      7527
Wed May 22 12:37:13 2019. At 14273 s, all done.
